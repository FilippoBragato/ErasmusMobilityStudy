{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import needed stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkscience as ns\n",
    "import pycountry as pc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mobility of Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_position(score_df, label):\n",
    "    scores = score_df.sort_values(label, ascending=False)\n",
    "    scores[label+' position']= (np.arange(len(scores.index))+1)\n",
    "    return scores\n",
    "def analysis(country_df):\n",
    "    country_df = country_df[country_df['Participant Profile']=='Learner']\n",
    "    country_df = country_df[country_df['Activity (mob)'].str.contains('Student')]\n",
    "    country_df = country_df[~country_df['Activity (mob)'].str.contains('traineeship')]\n",
    "    nodes = np.array(list(set.union(set(country_df.loc[:, 'Sending Country Code' ]), set(country_df.loc[:, 'Receiving Country Code']))))\n",
    "    country_df.dropna(how='any', inplace=True)\n",
    "    # I don't want it to take forever\n",
    "    node_position = {}\n",
    "    for i, name in enumerate(nodes):\n",
    "        node_position[name] = i\n",
    "    nodes_df = pd.DataFrame({'Nodes': nodes})\n",
    "    country_df['SendId'] = (np.array(list(map(lambda x: node_position[x], country_df['Sending Country Code']))))\n",
    "    country_df['RecId']= (np.array(list(map(lambda x: node_position[x], country_df['Receiving Country Code']))))\n",
    "    # Adjacency matrix\n",
    "    country_serie = country_df[['SendId', 'RecId', 'Participants']].groupby(['SendId', 'RecId']).sum()\n",
    "    row = np.array(country_serie.index.get_level_values(1).tolist())\n",
    "    col = np.array(country_serie.index.get_level_values(0).tolist())\n",
    "    val = country_serie.values\n",
    "    adj_matrix_crs = sparse.csr_matrix((val.flatten(), (row, col)), shape=(nodes.size, nodes.size))\n",
    "\n",
    "    def replace_iso3166(alpha):\n",
    "        try:\n",
    "            return pc.countries.get(alpha_2=alpha).name\n",
    "        except:\n",
    "            return alpha\n",
    "\n",
    "    country_df['Receiving Country Code']= (np.array(list(map(lambda x: replace_iso3166(x), country_df['Receiving Country Code']))))\n",
    "    country_df['Sending Country Code']= (np.array(list(map(lambda x: replace_iso3166(x), country_df['Sending Country Code']))))\n",
    "    nodes_df['Nodes'] = (np.array(list(map(lambda x: replace_iso3166(x), nodes_df['Nodes']))))\n",
    "\n",
    "    ns.visualize_adj(adj_matrix_crs)\n",
    "    matr = adj_matrix_crs.toarray()\n",
    "    matr[matr>1]=1\n",
    "    matr = matr - matr.T\n",
    "    fig, ax = plt.subplots(figsize=(6,5))\n",
    "    sns.heatmap(matr, cmap=\"Blues\", ax=ax)\n",
    "    plt.show()\n",
    "    country_df.rename({'Sending Country Code': 'source', 'Receiving Country Code':'target', 'Participants':'weight'},axis=1, inplace=True)\n",
    "    components = ns.find_components(adj_matrix_crs, nodes_df)\n",
    "    unique, counts = np.unique(components['component'], return_counts=True)\n",
    "    print('Number of components =', len(unique))\n",
    "    scores = ns.degree_disribution(adj_matrix_crs, nodes_df, print_graph=True)\n",
    "    ns.display_top_n(scores, 10, 'in degree')\n",
    "    ns.display_top_n(scores, 10, 'out degree')\n",
    "    df = ns.hits_alg(adj_matrix_crs, nodes_df, score_df=scores, print_graph=True)\n",
    "    scores = pd.merge(scores, df, on='Nodes')\n",
    "    ns.display_top_n(scores, 10, 'hits hub')\n",
    "    ns.display_top_n(scores, 10, 'hits autority')\n",
    "    df = ns.pagerank_alg(adj_matrix_crs, nodes_df, score_df=scores, print_graph=True)\n",
    "    scores = pd.merge(scores, df, on='Nodes')\n",
    "\n",
    "    ns.display_top_n(scores, 10, 'PageRank hub')\n",
    "    ns.display_top_n(scores, 10, 'PageRank authority')\n",
    "\n",
    "    sns.pairplot(scores)\n",
    "    plt.show()\n",
    "    scores = create_position(scores, 'in degree')\n",
    "    scores = create_position(scores, 'out degree')\n",
    "    scores = create_position(scores, 'hits hub')\n",
    "    scores = create_position(scores, 'hits autority')\n",
    "    scores = create_position(scores, 'PageRank hub')\n",
    "    scores = create_position(scores, 'PageRank authority')\n",
    "    scores.sort_index(inplace=True)\n",
    "    n = 40\n",
    "    pd.set_option('display.max_rows', n)\n",
    "    display(scores.sort_values('PageRank authority', ascending=False)[['Nodes', 'in degree', 'in degree position', 'hits autority', 'hits autority position', 'PageRank authority', 'PageRank authority position']].head(n))\n",
    "    display(scores.sort_values('PageRank hub', ascending=False)[['Nodes', 'out degree', 'out degree position', 'hits hub', 'hits hub position', 'PageRank hub', 'PageRank hub position']].head(n))\n",
    "    edges = country_df[['source','target']].copy()\n",
    "    ns.assortativity_calc(edges, adj_matrix_crs, nodes_df, True)\n",
    "    # label = 'PageRank autority position'\n",
    "    label = 'in degree position'\n",
    "    c = country_df.drop(['SendId', 'RecId'],axis=1)\n",
    "    another_order = scores[['Nodes', label]].copy()\n",
    "    another_order[label] = another_order[label] - 1\n",
    "    another_order.rename({'Nodes':'source', label: 'source ID'}, axis=1, inplace=True)\n",
    "    c = pd.merge(c, another_order, on=\"source\")\n",
    "    another_order.rename({'source':'target', 'source ID': 'target ID'}, axis=1, inplace=True)\n",
    "    c = pd.merge(c, another_order, on=\"target\")\n",
    "    c = c[['source ID', 'target ID', 'weight']]\n",
    "    c_serie = c.groupby(['source ID', 'target ID']).sum()\n",
    "    row = np.array(c_serie.index.get_level_values(1).tolist())\n",
    "    col = np.array(c_serie.index.get_level_values(0).tolist())\n",
    "    val = c_serie.values\n",
    "    or_adj = sparse.csr_matrix((val.flatten(), (row, col)), shape=(nodes.size, nodes.size))\n",
    "\n",
    "    ns.visualize_adj(or_adj)\n",
    "    matr = or_adj.toarray()\n",
    "    matr[matr>1]=1\n",
    "    matr = matr - matr.T\n",
    "    fig, ax = plt.subplots(figsize=(6,5))\n",
    "    sns.heatmap(matr, cmap=\"Blues\", ax=ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country19_df = pd.read_csv('data\\Erasmus19.csv', sep=';',low_memory=False, header=0, encoding='utf8')\n",
    "analysis(country19_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country18_df = pd.read_csv('data\\Erasmus18.csv', sep=';',low_memory=False, header=0, encoding='utf8')\n",
    "analysis(country18_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country17_df = pd.read_csv('data\\Erasmus17.csv', sep=';',low_memory=False, header=0, encoding='utf8')\n",
    "analysis(country17_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country16_df = pd.read_csv('data\\Erasmus16.csv', sep=';',low_memory=False, header=0, encoding='utf8')\n",
    "analysis(country16_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country15_df = pd.read_csv('data\\Erasmus15.csv', sep=';',low_memory=False, header=0, encoding='utf8')\n",
    "analysis(country15_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country14_df = pd.read_csv('data\\Erasmus14.csv', sep=';',low_memory=False, header=0, encoding='utf8')\n",
    "analysis(country14_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = country19_df.append(country18_df)\n",
    "country_df = country_df.append(country17_df)\n",
    "country_df = country_df.append(country16_df)\n",
    "country_df = country_df.append(country15_df)\n",
    "country_df = country_df.append(country14_df)\n",
    "analysis(country_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is only a draft version of community detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# import community\n",
    "\n",
    "G = nx.convert_matrix.from_scipy_sparse_matrix(adj_matrix_crs)\n",
    "p = nx.algorithms.community.modularity_max.greedy_modularity_communities(G)\n",
    "node_comm = nodes_df.copy()\n",
    "\n",
    "node_comm['Community']=np.zeros(len(node_comm.index),dtype='int8')\n",
    "for i, set in enumerate(p):\n",
    "    for element in set:\n",
    "        node_comm.iat[element, 1]=i\n",
    "for i, set in enumerate(p):\n",
    "    display(node_comm[node_comm['Community']==i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographic Heat map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "geo_df = gpd.read_file('countries.geojson')\n",
    "\n",
    "def replace_iso2(alpha):\n",
    "    try:\n",
    "        return pc.countries.get(alpha_3=alpha).alpha_2\n",
    "    except:\n",
    "        return alpha\n",
    "    \n",
    "geo_df['iso2_code']= (np.array(list(map(lambda x: replace_iso2(x), geo_df['ISO_A3']))))\n",
    "\n",
    "geo_df.columns = ['country', 'country_code', 'geometry', 'iso2_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# adding code country to scores dataframe\n",
    "countries_codes = nodes_df\n",
    "countries_codes['code'] = nodes\n",
    "scores_merge = pd.merge(left=countries_codes, right=scores, how='right', left_on='Nodes', right_on='Nodes')\n",
    "\n",
    "# in geo_df United Kingdom has code GB, so we have to change it manually\n",
    "geo_df.loc[geo_df['country'] == 'United Kingdom', 'iso2_code'] = 'UK'\n",
    "geo_df.loc[geo_df['country'] == 'Greece', 'iso2_code'] = 'EL'\n",
    "geo_df.loc[geo_df['country'] == 'Kosovo', 'iso2_code'] = 'XK'\n",
    "geo_df.loc[geo_df['country'] == 'Czech Republic', 'country'] = 'Czechia'\n",
    "geo_df.loc[geo_df['country'] == 'Republic of Serbia', 'country'] = 'Serbia'\n",
    "\n",
    "# adding Switzerland since there is no Erasmus data\n",
    "sw = {'Nodes':'Switzerland', 'code':'CH', 'in degree':0, 'out degree':0, 'hits hub':0, 'hits autority':0,\n",
    "       'PageRank hub':0, 'PageRank authority':0, 'in degree position':0,\n",
    "       'out degree position':0, 'hits hub position':0, 'hits autority position':0,\n",
    "       'PageRank hub position':0, 'PageRank authority position':0}\n",
    "scores_merge = scores_merge.append(sw, ignore_index = True)\n",
    "\n",
    "merged_df = pd.merge(left=geo_df, right=scores_merge, how='right', left_on='iso2_code', right_on='code')\n",
    "merged_df.dropna(subset=['Nodes'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "european_countries = ['Germany', 'United Kingdom', 'France', 'Italy', 'Spain', 'Ukraine', 'Poland', 'Romania', \n",
    "                'Netherlands', 'Belgium', 'Czechia', 'Greece', 'Portugal', 'Sweden', 'Hungary', \n",
    "                'Belarus', 'Austria', 'Serbia', 'Switzerland', 'Bulgaria', 'Denmark', 'Finland', 'Slovakia', 'Norway',\n",
    "                'Ireland', 'Croatia', 'Moldova', 'Bosnia and Herzegovina', 'Albania', 'Lithuania', 'Macedonia', \n",
    "                'Slovenia', 'Latvia', 'Estonia', 'Montenegro', 'Luxembourg', 'Malta', 'Iceland', 'Andorra', 'Monaco', \n",
    "                'Liechtenstein', 'Kosovo', 'Turkey']\n",
    "# Russia has not been taken in consideration since it was too big to show and has very low exchanges\n",
    "\n",
    "european_df = merged_df[merged_df['country'].isin(european_countries)]\n",
    "\n",
    "# Countries ordered by PageRank hub score\n",
    "display(european_df[['country', 'PageRank hub']].sort_values('PageRank hub', ascending=False))\n",
    "# Countries ordered by PageRank authority score\n",
    "display(european_df[['country', 'PageRank authority']].sort_values('PageRank authority', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deg_list = ['in degree', 'out degree', 'PageRank hub', 'PageRank autority']\n",
    "#fig4, ax4 = plt.subplots(1,4, figsize=(20,15))\n",
    "plt_list = ['PageRank hub', 'PageRank authority']\n",
    "fig4, ax4 = plt.subplots(1,2, figsize=(20,15))\n",
    "\n",
    "for i in range(len(plt_list)):\n",
    "    european_df.plot(column=plt_list[i], ax=ax4[i], edgecolor='0.8', linewidth=1, cmap='Reds')\n",
    "    sm = plt.cm.ScalarMappable(norm=plt.Normalize(vmin=european_df[plt_list[i]].min(), \n",
    "                                              vmax=european_df[plt_list[i]].max()), cmap='Reds')\n",
    "    ax4[i].axis('off')\n",
    "    fig4.colorbar(sm, ax=ax4[i], shrink=0.25)\n",
    "    ax4[i].set_title('European countries heatmap - ' + plt_list[i], fontsize=15)\n",
    "\n",
    "# ax4 = np.reshape(ax4, (2,2))\n",
    "# plt.savefig('eu_pagerank.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erasmus exchanges vs total students enrolled per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset containing for each european university the students enrolled in ISCED 5-7 (tertiary education and master degree)\n",
    "isced57_df = pd.read_csv(\"eter-export-2016.csv\", delimiter=';', on_bad_lines='skip')\n",
    "isced57_df.dropna(inplace=True)\n",
    "for index in range(len(isced57_df['Institution Name'])):\n",
    "    if isced57_df.iat[index,0] != isced57_df.iat[index,0].upper():\n",
    "        isced57_df.iat[index,0] = isced57_df.iat[index,0].upper()\n",
    "        \n",
    "# dropping all the values having too many numbers after comma\n",
    "mask = isced57_df['Total students enrolled ISCED 5-7'].str.contains(',', na=False)\n",
    "isced57_df = isced57_df[~mask]\n",
    "\n",
    "# dropping rows with undefined values\n",
    "isced57_df = isced57_df[~isced57_df['Total students enrolled ISCED 5-7'].isin(['m','a','c','xr','s'])]\n",
    "\n",
    "# changing country codes accordingly to european_df ones\n",
    "isced57_df['Country Code'][isced57_df['Country Code'] == 'GR'] = 'EL'\n",
    "\n",
    "isced57_df['Total students enrolled ISCED 5-7'] = isced57_df['Total students enrolled ISCED 5-7'].astype(float)\n",
    "isced57_df['Total students enrolled ISCED 5-7'] = isced57_df['Total students enrolled ISCED 5-7'].round()\n",
    "# count total number of enrolled students for each country\n",
    "isced57_df = isced57_df.groupby(['Country Code'])['Total students enrolled ISCED 5-7'].sum().reset_index()\n",
    "\n",
    "european_df_w = pd.merge(left=isced57_df, right=european_df, how='right', left_on='Country Code', right_on='iso2_code')\n",
    "european_df_w = gpd.GeoDataFrame(european_df_w, geometry = 'geometry')\n",
    "\n",
    "print('Top 10 countries for students enrollment')\n",
    "display(european_df_w[['country', 'Total students enrolled ISCED 5-7']].sort_values('Total students enrolled ISCED 5-7',\n",
    "                                                                                    ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "european_df_w['weight_pr_hub'] = european_df_w['PageRank hub']/european_df_w['Total students enrolled ISCED 5-7']\n",
    "european_df_w['weight_pr_aut'] = european_df_w['PageRank authority']/european_df_w['Total students enrolled ISCED 5-7']\n",
    "\n",
    "# threshold set because some countries had too big values wrt the average\n",
    "european_df_w.loc[european_df_w['weight_pr_hub'] > 2*10**(-7), 'weight_pr_hub'] = 2*10**(-7)\n",
    "european_df_w.loc[european_df_w['weight_pr_aut'] > 2*10**(-7), 'weight_pr_aut'] = 2*10**(-7)\n",
    "# maybe set better this thresholds\n",
    "\n",
    "eu_w_copy = european_df_w.copy()\n",
    "eu_w_copy.dropna(inplace = True)\n",
    "# Countries ordered by weighted PageRank hub score\n",
    "eu_w_copy.sort_values('weight_pr_hub', ascending=False, inplace=True)\n",
    "eu_w_copy.reset_index(drop=True, inplace=True)\n",
    "display(eu_w_copy[['country', 'weight_pr_hub']])\n",
    "# Countries ordered by weighted PageRank authority score\n",
    "eu_w_copy.sort_values('weight_pr_aut', ascending=False, inplace=True)\n",
    "eu_w_copy.reset_index(drop=True, inplace=True)\n",
    "display(eu_w_copy[['country', 'weight_pr_aut']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig7, ax7 = plt.subplots(1,2, figsize=(20,15))\n",
    "plt_list = ['weight_pr_hub', 'weight_pr_aut']\n",
    "for i in range(len(plt_list)):\n",
    "    # european_df_w.drop(european_df_w[plt_list[i]].idxmax(), inplace=True)\n",
    "    european_df_w.plot(column=plt_list[i], ax=ax7[i], edgecolor='0.8', linewidth=1, cmap='Reds')\n",
    "    sm = plt.cm.ScalarMappable(norm=plt.Normalize(vmin=european_df_w[plt_list[i]].min(), \n",
    "                                              vmax=european_df_w[plt_list[i]].max()), cmap='Reds')\n",
    "    ax7[i].axis('off')\n",
    "    fig7.colorbar(sm, ax=ax7[i], shrink=0.25)\n",
    "    ax7[i].set_title('European countries heatmap - ' + plt_list[i], fontsize=15)\n",
    "    \n",
    "# plt.savefig('eu_pagerank_weight.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoPlot for Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "node_comm.loc[node_comm['Nodes'] == 'Moldova, Republic of', 'Nodes'] = 'Moldova'\n",
    "node_comm.loc[node_comm['Nodes'] == 'North Macedonia', 'Nodes'] = 'Macedonia'\n",
    "node_comm.loc[node_comm['Nodes'] == 'XK', 'Nodes'] = 'Kosovo'\n",
    "\n",
    "eu_communities = european_df.copy()\n",
    "eu_communities['Community'] = node_comm[node_comm['Nodes'].isin(european_countries)]['Community']\n",
    "\n",
    "fig5, ax5 = plt.subplots(figsize=(10,10))\n",
    "eu_communities.plot(column='Community', ax=ax5, edgecolor='0.8', linewidth=1, cmap='jet')\n",
    "ax5.axis('off')\n",
    "ax5.set_title('European countries - Commmunity', fontsize=15)\n",
    "\n",
    "# plt.savefig('eu_community.png')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81216a00e87de3644468e89fc1953fa1003fc6eb0b10b1ab2fbdfc367991563d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
